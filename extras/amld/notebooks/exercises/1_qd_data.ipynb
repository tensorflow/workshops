{"nbformat_minor": 2, "nbformat": 4, "cells": [{"source": ["# Quickdraw Data\n", "\n", "If machine learning is rocket science then data is your fuel! So before\n", "doing anything we will have a close look at the data available and spend\n", "some time bringing it into the \"right\" form (i.e.\n", "[tf.train.Example](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/train/Example)).\n", "\n", "That's why we start by spending quite a lot on this notebook, downloading\n", "the data, understanding it, and transforming it into the right format for\n", "Tensorflow.\n", "\n", "The data used in this workshop is taken from Google's quickdraw (click on\n", "the images to see loads of examples):\n", "\n", "https://quickdraw.withgoogle.com/data\n", "\n", "Table of contents:\n", "\n", "- [ 1 Get the data](#1-Get-the-data)\n", "- [ 2 Inspect the data](#2-Inspect-the-data)\n", "- [ 3 Rasterize](#3-Rasterize)\n", "- [ 4 tf.train.Example data format](#4-tf.train.Example-data-format)\n", "- [ 5 Create dataset](#5-Create-dataset)\n", "- [ 6 Prepare dataset for RNN \u2013\u00a0bonus!](#6-Prepare-dataset-for-RNN-%E2%80%93-bonus!)"], "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["import base64, io, itertools, json, os, random, re, time\n", "import numpy as np\n", "import tensorflow as tf\n", "from matplotlib import pyplot\n", "from PIL import Image, ImageDraw\n", "from IPython import display\n", "from six.moves.urllib import request\n", "from xml.dom import minidom\n", "\n", "%matplotlib inline\n", "# Always make sure you are using running the expected version.\n", "# There are considerable differences between versions...\n", "tf.__version__"], "outputs": [], "metadata": {}}, {"source": ["# 1 Get the data\n", "\n", "In this section we download a set of raw data files from the web."], "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# Retrieve list of classes.\n", "\n", "def list_bucket(bucket, regexp='.*'):\n", "    \"\"\"Returns a (filtered) list of Keys in specified GCE bucket.\"\"\"\n", "    keys = []\n", "    fh = request.urlopen('https://storage.googleapis.com/%s' % bucket)\n", "    content = minidom.parseString(fh.read())\n", "    for e in content.getElementsByTagName('Contents'):\n", "        key = e.getElementsByTagName('Key')[0].firstChild.data\n", "        if re.match(regexp, key):\n", "            keys.append(key)\n", "    return keys\n", "\n", "all_ndjsons = list_bucket('quickdraw_dataset', '.*ndjson$')\n", "print 'available: (%d)' % len(all_ndjsons)\n", "print ' '.join([key.split('/')[-1].split('.')[0] for key in all_ndjsons])"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# Store all data locally in this directory.\n", "data_path = '../data'\n", "\n", "# Mini group of two animals.\n", "pets = ['cat', 'dog']\n", "\n", "# Somewhat larger group of zoo animals.\n", "zoo = ['elephant', 'giraffe', 'kangaroo', 'lion', 'monkey', 'panda',\n", "       'penguin', 'rhinoceros', 'tiger', 'zebra']\n", "\n", "# Even larger group of all animals.\n", "animals = ['bat', 'bird', 'butterfly', 'camel', 'cat', 'cow', 'crab',\n", "           'crocodile', 'dog', 'dolphin', 'duck', 'elephant', 'fish',\n", "           'frog', 'giraffe', 'hedgehog', 'horse', 'kangaroo', 'lion',\n", "           'lobster', 'monkey', 'mosquito', 'mouse', 'octopus', 'owl',\n", "           'panda', 'parrot', 'penguin', 'pig', 'rabbit', 'raccoon',\n", "           'rhinoceros', 'scorpion', 'sea turtle', 'shark', 'sheep',\n", "           'snail', 'spider', 'squirrel', 'teddy-bear', 'tiger',\n", "           'whale', 'zebra']\n", "\n", "# Create your own group -- the more classes you include the more challenging\n", "# the classification task will be...\n", "\n", "# Choose one of above groups for remainder of workshop.\n", "# Note: This will result in ~100MB of download per class.\n", "classes, classes_name = zoo, 'zoo'"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# Download above chosen group.\n", "\n", "def valid_ndjson(filename):\n", "    \"\"\"Checks presence + completeness of .ndjson file.\"\"\"\n", "    try:\n", "        json.loads(open(filename).readlines()[-1])\n", "        return True\n", "    except ValueError, IOError:\n", "        return False\n", "\n", "def retrieve(bucket, key, filename):\n", "    \"\"\"Returns a file specified by its Key from a GCE bucket.\"\"\"\n", "    url = 'https://storage.googleapis.com/%s/%s' % (bucket, key)\n", "    if not os.path.isfile(filename):\n", "        request.urlretrieve(url=url, filename=filename)\n", "    while not valid_ndjson(filename):\n", "        print '*** Corrupted download (%.2f MB), retrying...' % (os.path.getsize(filename) / 2.**20)\n", "        request.urlretrieve(url=url, filename=filename)\n", "\n", "if not os.path.exists(data_path):\n", "    os.mkdir(data_path)\n", "\n", "print '\\n%d classes:' % len(classes)\n", "\n", "for name in classes:\n", "    print name,\n", "    dst = '%s/%s.ndjson' % (data_path, name)\n", "    retrieve('quickdraw_dataset', 'full/simplified/%s.ndjson' % name, dst)\n", "    print '%.2f MB' % (os.path.getsize(dst) / 2.**20)\n", "\n", "print '\\nDONE :)'"], "outputs": [], "metadata": {}}, {"source": ["# 2 Inspect the data\n", "\n", "What is the format of the downloaded files?"], "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# So let's check out the downloaded files...\n", "!ls $data_path"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# What is the NDJSON file format?\n", "# Seems to be one JSON dictionary per line...\n", "path = tf.gfile.Glob(os.path.join(data_path, '*.ndjson'))[1]\n", "print file(path).read()[:1000] + '...'"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# Parse single line.\n", "data_json = json.loads(file(path).readline())\n", "data_json.keys()"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# So we have some meta information...\n", "for k, v in data_json.iteritems():\n", "    if k != 'drawing':\n", "        print '%20s   ->   %s' % (k, v)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# ...and the actual drawing.\n", "drawing = data_json['drawing']\n", "# The drawing consists of a series of strokes:\n", "[np.array(stroke).shape for stroke in drawing]"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# Draw the image -- the strokes all have have shape (2, n)\n", "# so the first index seems to be x/y coordinate:\n", "for stroke in drawing:\n", "    pyplot.plot(np.array(stroke[0]), -np.array(stroke[1]))\n", "# Would YOU recognize this drawing successfully?"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["%%time\n", "# Some more code to load many sketches at once.\n", "# Let's ignore the difficult \"unrecognized\" sketches for now...\n", "# (i.e. unrecognized by the official quickdraw classifier)\n", "\n", "def convert(line):\n", "    \"\"\"Converts single line to JSON + converts 'drawing' to list of np.array.\"\"\"\n", "    d = json.loads(line)\n", "    d['drawing'] = [np.array(stroke) for stroke in d['drawing']]\n", "    return d\n", "\n", "def loaditer(name, unrecognized=False):\n", "    \"\"\"Returns iterable of drawings in specified file.\n", "\n", "    Args:\n", "      name: Name of the downloaded object (e.g. \"elephant\").\n", "      unrecognized: Whether to include drawings that were not recognized\n", "          by Google AI (i.e. the hard ones).\n", "    \"\"\"\n", "    for line in open('%s/%s.ndjson' % (data_path, name)):\n", "        d = convert(line)\n", "        if d['recognized'] or unrecognized:\n", "            yield d\n", "\n", "def loadn(name, n, unrecognized=False):\n", "    \"\"\"Returns list of drawings.\n", "\n", "    Args:\n", "      name: Name of the downloaded object (e.g. \"elephant\").\n", "      n: Number of drawings to load.\n", "      unrecognized: Whether to include drawings that were not recognized\n", "          by Google AI (i.e. the hard ones).\n", "    \"\"\"\n", "    it = loaditer(name, unrecognized=unrecognized)\n", "    return list(itertools.islice(it, 0, n))\n", "\n", "print 'loading some \"%s\"...' % classes[0]\n", "sample = loadn(classes[0], 100)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# Some more drawings...\n", "pyplot.figure(figsize=(10, 10))\n", "n = 3\n", "for x in range(n):\n", "    for y in range(n):\n", "        i = x * n + y\n", "        pyplot.subplot(n, n, i + 1)\n", "        for stroke in sample[i]['drawing']:\n", "            pyplot.plot(np.array(stroke[0]), -np.array(stroke[1]))"], "outputs": [], "metadata": {}}, {"source": ["# 3 Rasterize\n", "\n", "Idea: After converting the raw drawing data into rasterized images, we can\n", "use [MNIST](https://www.tensorflow.org/get_started/mnist/beginners)-like\n", "image processing to classify the drawings."], "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["%%writefile _derived/1_json_to_img.py\n", "# (Written into separate file for sharing between notebooks.)\n", "\n", "# Function that converts drawing (specified by individual strokes)\n", "# to a rendered black/white image.\n", "\n", "def json_to_img(drawing, img_sz=64, lw=3, maximize=True):\n", "    img = Image.new('L', (img_sz, img_sz))\n", "    draw = ImageDraw.Draw(img)\n", "    lines = np.array([\n", "        stroke[0:2, i:i+2]\n", "        for stroke in drawing['drawing']\n", "        for i in range(stroke.shape[1] - 1)\n", "    ], dtype=np.float32)\n", "    if maximize:\n", "        for i in range(2):\n", "            min_, max_ = lines[:,i,:].min() * 0.95, lines[:,i,:].max() * 1.05\n", "            lines[:,i,:] = (lines[:,i,:] - min_) / max(max_ - min_, 1)\n", "    else:\n", "        lines /= 1024\n", "    for line in lines:\n", "        draw.line(tuple(line.T.reshape((-1,)) * img_sz), fill='white', width=lw)\n", "    return img"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# (Load code from previous cell -- make sure to have executed above cell first.)\n", "%run -i _derived/1_json_to_img.py\n", "\n", "# Show some examples.\n", "\n", "def showimg(img):\n", "    if isinstance(img, np.ndarray):\n", "        img = Image.fromarray(img, 'L')\n", "    b = io.BytesIO()\n", "    img.convert('RGB').save(b, format='png')\n", "    enc = base64.b64encode(b.getvalue()).decode('utf-8')\n", "    display.display(display.HTML(\n", "        '<img src=\"data:image/png;base64,%s\">' % enc))\n", "\n", "# Fetch some images + shuffle order.\n", "rows, cols = 10, 10\n", "n_per_class = rows * cols // len(classes) + 1\n", "drawings_matrix = [loadn(name, rows*cols) for name in classes]\n", "drawings_list = reduce(lambda x, y: x + y, drawings_matrix, [])\n", "drawings_list = np.random.permutation(drawings_list)\n", "\n", "# Create mosaic of rendered images.\n", "lw = 4\n", "img_sz = 64\n", "tableau = np.zeros((img_sz * rows, img_sz * cols), dtype=np.uint8)\n", "for y in range(rows):\n", "    for x in range(cols):\n", "        i = y * rows + x\n", "        img = json_to_img(drawings_list[i], img_sz=img_sz, lw=lw, maximize=True)\n", "        tableau[y*img_sz:(y+1)*img_sz, x*img_sz:(x+1)*img_sz] = np.asarray(img)\n", "\n", "showimg(tableau)"], "outputs": [], "metadata": {}}, {"source": ["# 4 tf.train.Example data format\n", "\n", "Tensorflow's \"native\" format for data storage is the `tf.train.Example`\n", "[protocol buffer](https://en.wikipedia.org/wiki/Protocol_Buffers).\n", "\n", "In this section we briefly explore the API needed to access the data\n", "inside the `tf.train.Example` protocol buffer. It's **not necessary** to read\n", "through the\n", "[Python API documentation](https://developers.google.com/protocol-buffers/docs/pythontutorial)."], "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# Create a new (empty) instance.\n", "example = tf.train.Example()\n", "# (empty example will print nothing)\n", "print example"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# An example contains a map from feature name to \"Feature\".\n", "# Every \"Feature\" contains a list of elements of the same\n", "# type, which is one of:\n", "# - bytes_list (similar to Python's \"str\")\n", "# - float_list (float number)\n", "# - int64_list (integer number)\n", "\n", "# These values can be accessed as follows (no need to understand\n", "# details):\n", "\n", "# Add float value \"3.1416\" to feature \"magic_numbers\"\n", "example.features.feature['magic_numbers'].float_list.value.append(3.1416)\n", "# Add some more values to the float list \"magic_numbers\".\n", "example.features.feature['magic_numbers'].float_list.value.extend([2.7183, 1.4142, 1.6180])\n", "\n", "# YOUR ACTION REQUIRED:\n", "# Create a second feature named \"adversaries\" and add the elements\n", "# \"Alice\" and \"Bob\".\n", "example.features.feature['adversaries'].\n", "\n", "# This will now print a serialized representation of our protocol buffer\n", "# with features \"magic_numbers\" and \"adversaries\" set...\n", "print example\n", "\n", "# .. et voila : that's all you need to know about protocol buffers\n", "# for this workshop."], "outputs": [], "metadata": {}}, {"source": ["# 5 Create dataset\n", "\n", "Now let's create a \"dataset\" of `tf.train.Example`\n", "[protocol buffers](https://developers.google.com/protocol-buffers/) (\"protos\").\n", "\n", "A single example contains all the information for a drawing (i.e. rasterized\n", "image, label, and meta information).\n", "\n", "A dataset consists of non-overlapping sets of examples that will be used for\n", "training and evaluation of the classifier (the \"test\" set will be used for the\n", "final evaluation). Because these files can quickly become very large, we\n", "\"shard\" them into multiple smaller files of equal size."], "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# Let's first check how many [recognized=True] examples we have in each class.\n", "# Depending on your choice of classes you could generate up to 200k examples...\n", "for name in classes:\n", "    print name, len(list(open('%s/%s.ndjson' % (data_path, name)))), 'recognized', len(list(loaditer(name)))"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# Helper code to create sharded recordio files.\n", "# (No need to read through this.)\n", "\n", "# Well... Since you continue to read through this cell, I could as\n", "# well explain in more detail what it is about :-)\n", "# Because we work with large amounts of data, we will create \"sharded\"\n", "# files, that is, we split a single dataset into a number of files, like\n", "# train-00000-of-00005, ..., train-00004-of-00005 (if we're using 5 shards).\n", "# This way we have smaller individual files, and we can also easily access\n", "# e.g. 20% of all data, or have 5 threads reading through the data\n", "# simultaneously.\n", "\n", "# The code in this cell simply takes a list of iterators and then\n", "# randomly distributes the values returned by these iterators into sharded\n", "# datasets (e.g. a train/eval/test split).\n", "\n", "def rand_key(counts):\n", "    \"\"\"Returns a random key from \"counts\", using values as distribution.\"\"\"\n", "    r = random.randint(0, sum(counts.values()))\n", "    for key, count in counts.iteritems():\n", "        if r > count or count == 0:\n", "            r -= count\n", "        else:\n", "            counts[key] -= 1\n", "            return key\n", "\n", "def make_sharded_files(make_example, path, classes, iters, splits,\n", "                       shards=10, overwrite=False, report_dt=10):\n", "    \"\"\"Create sharded files from \"iters\".\n", "\n", "    Args:\n", "      make_example: Converts object returned by elements of \"iters\"\n", "          to tf.train.Example() proto.\n", "      path: Directory that will contain recordio files.\n", "      classes: Names of classes, will be written to \"labels.txt\".\n", "      splits: Dictionary mapping filename to number of examples (of\n", "          every class).\n", "      shards: Number of files to be created per split.\n", "      overwrite: Whether a pre-existing directory should be overwritten.\n", "      report_dt: Number of seconds between status updates (0=no updates).\n", "\n", "    Returns:\n", "      Total number of examples written to disk (this should be equal to\n", "      the number of classes times the sum of the number of examples of\n", "      all the splits).\n", "    \"\"\"\n", "    assert len(iters) == len(classes)\n", "    if not os.path.exists(path):\n", "        os.makedirs(path)\n", "    paths = {\n", "        split: ['%s/%s-%05d-of-%05d' % (path, split, i, shards)\n", "                for i in range(shards)]\n", "        for split in splits\n", "    }\n", "    assert overwrite or not os.path.exists(paths.values()[0][0])\n", "    writers = {\n", "        split: [tf.python_io.TFRecordWriter(ps[i]) for i in range(shards)]\n", "        for split, ps in paths.iteritems()\n", "    }\n", "    t0 = time.time()\n", "    n = sum(splits.values())\n", "    examples = 0\n", "    for i in range(n):\n", "        split = rand_key(splits)\n", "        writer = writers[split][splits[split] % shards]\n", "        for j in range(len(classes)):\n", "            example = make_example(j, iters[j].next())\n", "            writer.write(example.SerializeToString())\n", "            examples += 1\n", "        remaining = sum(splits.values())\n", "        if report_dt > 0 and time.time() - t0 > report_dt:\n", "            print 'processed %d/%d (%.2f%%)' % (i, n, 100. * i / n)\n", "            t0 = time.time()\n", "    for split in splits:\n", "        for writer in writers[split]:\n", "            writer.close()\n", "    with open('%s/labels.txt' % path, 'w') as f:\n", "        f.write('\\n'.join(classes))\n", "    return examples"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["%%writefile _derived/1_make_example_img.py\n", "# (Written into separate file for sharing between notebooks.)\n", "\n", "# Convert drawing tf.train.Example proto.\n", "# Uses json_to_img() from previous cell to create raster image.\n", "\n", "def make_example_img(label, drawing):\n", "    example = tf.train.Example()\n", "    example.features.feature['label'].int64_list.value.append(label)\n", "    img_64 = np.asarray(json_to_img(drawing, img_sz=64, lw=4, maximize=True)).reshape(-1)\n", "    example.features.feature['img_64'].int64_list.value.extend(img_64)\n", "    example.features.feature['countrycode'].bytes_list.value.append(drawing['countrycode'].encode())\n", "    example.features.feature['recognized'].int64_list.value.append(drawing['recognized'])\n", "    example.features.feature['word'].bytes_list.value.append(drawing['word'].encode())\n", "    ts = drawing['timestamp']\n", "    ts = time.mktime(time.strptime(ts[:ts.index('.')], '%Y-%m-%d %H:%M:%S'))\n", "    example.features.feature['timestamp'].int64_list.value.append(long(ts))\n", "    example.features.feature['key_id'].int64_list.value.append(long(drawing['key_id']))\n", "    return example"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# (Load code from previous cell -- make sure to have executed above cell first.)\n", "%run -i _derived/1_make_example_img.py\n", "\n", "# Create the (rasterized) dataset.\n", "\n", "path = '%s/dataset_img' % data_path\n", "t0 = time.time()\n", "n = make_sharded_files(\n", "    make_example=make_example_img,\n", "    path=path,\n", "    classes=classes,\n", "    iters=[loaditer(name) for name in classes],\n", "    # Note: We only generate few examples here so you won't be\n", "    # blocked for too long while waiting for this cell to finish.\n", "    # You can re-run the cell with larger values (don't forget to\n", "    # update \"path\" above) in the background to get a larger\n", "    # dataset...\n", "    splits=dict(train=5000, eval=1000, test=1000),\n", "    overwrite=True,\n", ")\n", "\n", "print 'stored data to \"%s\"' % path\n", "print 'generated %d examples in %d seconds' % (n, time.time() - t0)"], "outputs": [], "metadata": {}}, {"source": ["# 6 Prepare dataset for RNN \u2013\u00a0bonus!\n", "\n", "This section creates another dataset of example protos that contain the raw\n", "stroke data, suitable for usage with a recurrent neural network.\n", "\n", "Note that later notebooks will have a \"bonus\" section that uses this dataset,\n", "but the \"non-bonus\" parts can be worked through without executing below\n", "cells..."], "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["%%writefile _derived/1_json_to_stroke.py\n", "# (Written into separate file for sharing between notebooks.)\n", "\n", "# Convert stroke coordinates into normalized relative coordinates,\n", "# one single list, and add a \"third dimension\" that indicates when\n", "# a new stroke starts.\n", "\n", "def json_to_stroke(d):\n", "    norm = lambda x: (x - x.min()) / max(1, (x.max() - x.min()))\n", "    xy = np.concatenate([np.array(s, dtype=np.float32) for s in d['drawing']], axis=1)\n", "    z = np.zeros(xy.shape[1])\n", "    if len(d['drawing']) > 1:\n", "        z[np.cumsum(np.array(map(lambda x: x.shape[1], d['drawing'][:-1])))] = 1\n", "    dxy = np.diff(norm(xy))\n", "    return np.concatenate([dxy, z.reshape((1, -1))[:, 1:]])"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# (Load code from previous cell -- make sure to have executed above cell first.)\n", "%run -i _derived/1_json_to_stroke.py\n", "\n", "# Visualize / control output of json_to_stroke().\n", "\n", "stroke = json_to_stroke(sample[3])\n", "# First 2 dimensions are normalized dx/dy coordinates\n", "# third dimension indicates \"new stroke\".\n", "xy = stroke[:2, :].cumsum(axis=1)\n", "pyplot.plot(*xy)\n", "pxy = xy[:, stroke[2] != 0]\n", "pyplot.plot(pxy[0], pxy[1], 'ro')"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["%%writefile _derived/1_make_example_stroke.py\n", "# (Written into separate file for sharing between notebooks.)\n", "\n", "# Convert drawing tf.train.Example proto.\n", "# Uses json_to_stroke() from previous cell to create raster image.\n", "\n", "def make_example_stroke(label, drawing):\n", "    example = tf.train.Example()\n", "    example.features.feature['label'].int64_list.value.append(label)\n", "    stroke = json_to_stroke(drawing)\n", "    example.features.feature['stroke_x'].float_list.value.extend(stroke[0, :])\n", "    example.features.feature['stroke_y'].float_list.value.extend(stroke[1, :])\n", "    example.features.feature['stroke_z'].float_list.value.extend(stroke[2, :])\n", "    example.features.feature['stroke_len'].int64_list.value.append(stroke.shape[1])\n", "    example.features.feature['countrycode'].bytes_list.value.append(drawing['countrycode'].encode())\n", "    example.features.feature['recognized'].int64_list.value.append(drawing['recognized'])\n", "    example.features.feature['word'].bytes_list.value.append(drawing['word'].encode())\n", "    ts = drawing['timestamp']\n", "    ts = time.mktime(time.strptime(ts[:ts.index('.')], '%Y-%m-%d %H:%M:%S'))\n", "    example.features.feature['timestamp'].int64_list.value.append(long(ts))\n", "    example.features.feature['key_id'].int64_list.value.append(long(drawing['key_id']))\n", "    return example"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# (Load code from previous cell -- make sure to have executed above cell first.)\n", "%run -i _derived/1_make_example_stroke.py\n", "\n", "# Create the (stroke) dataset.\n", "\n", "path = '%s/dataset_stroke' % data_path\n", "t0 = time.time()\n", "n = make_sharded_files(\n", "    make_example=make_example_stroke,\n", "    path=path,\n", "    classes=classes,\n", "    iters=[loaditer(name) for name in classes],\n", "    splits=dict(train=50000, eval=10000, test=10000),\n", "    overwrite=True,\n", ")\n", "\n", "print 'stored examples to \"%s\"' % path\n", "print 'generated %d examples in %d seconds' % (n, time.time() - t0)"], "outputs": [], "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "version": "2.7.9", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}