{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use shift+enter to run each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_lattice\n",
    "import tensorflow as tf\n",
    "import tensorflow_lattice as tfl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check TensorFlow version. We expect >= 1.4.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"You have version %s\" % tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the default graph to clean up things.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholder is a way to feed a data from python to a computational graph.\n",
    "# x is a 2d tensor with shape [?, 2].\n",
    "#\n",
    "# In TensorFlow, the first dimension is usually reserved for a batch size.\n",
    "# Often we want to tune the batch size for SGD to maximize the througput during\n",
    "# the training, batch_size is usually set to \"None\" to let TensorFlow know the\n",
    "# size is unknown when we create the graph.\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "\n",
    "# Here we use lattice_layer to define a lattice model.\n",
    "# lattice_layer expects 2d tensor [batch_size, input_dim] as an input.\n",
    "# In this case, since x's shape is [?, 2], batch_size is unknown, but\n",
    "# input_dim == 2.\n",
    "# Here we set lattice_sizes = (2, 2) which means this lattice_layer defines\n",
    "# 2 x 2 lattice.\n",
    "# lattice_layer returns 4 elements: \n",
    "#  1. output tensor\n",
    "#  2. lookup param tensor\n",
    "#  3. Projection operator\n",
    "#  4. regularization loss (scalar tensor)\n",
    "#\n",
    "# We will cover other three components later, so let's focus on the output\n",
    "# tensor.\n",
    "# The output tensor is the output of this layer. Its shape is\n",
    "# [batch_size, output_dim], where the default output_dim == 1.\n",
    "# So in this case, y's shape is [?, 1].\n",
    "(y, _, _, _) = tfl.lattice_layer(x, lattice_sizes=(2, 2))\n",
    "\n",
    "# Run Session to get the value. Feel free to feed different values other than\n",
    "# [[0.0, 0.0]].\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result = sess.run(y, feed_dict={x: [[0.0, 0.0]]})\n",
    "\n",
    "# We expect 0.0 as an output\n",
    "assert (result[0][0]) < 1e-7\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether matplotlib is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# create some data using numpy. y = x * 0.1 + 0.3 + noise\n",
    "x = np.random.rand(100).astype(np.float32)\n",
    "noise = np.random.normal(scale=0.01, size=len(x))\n",
    "y = x\n",
    "\n",
    "# plot it\n",
    "plt.plot(x, y, '.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-lattice",
   "language": "python",
   "name": "tf-lattice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
