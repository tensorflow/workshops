{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning using Tensorflow\n",
    "\n",
    "In this notebook we will solve two simple exercises using low-level\n",
    "Tensorflow.\n",
    "\n",
    "Table of Contents:\n",
    "\n",
    "- [ 1 Iterative division](#1-Iterative-division)\n",
    "- [ 2 Neural function approximator](#2-Neural-function-approximator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "# Always make sure you are using running the expected version.\n",
    "# There are considerable differences between versions...\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i _derived/2_visualize_graph.py\n",
    "# (Load code helper code cell -- make sure to have executed notebook \"2_tf_basics\" first.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Iterative division\n",
    "\n",
    "Using [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "to iteratively solve a division:\n",
    "We first define our graph `a_times_b = a * b` and then we provide both\n",
    "`a` and `a_times_b`, and set an initial guess of `b` to zero. We then\n",
    "iteratively improve our guess for `b` by minimizing the square of the\n",
    "difference of `a_times_b` (=target) and `a * b`.\n",
    "\n",
    "Note that we do not need to specify any gradients -- Tensorflow's\n",
    "`GradientDescentOptimizer` can simply look at our \"forward graph\" and\n",
    "then generate a \"backward graph\" starting from our loss that consists\n",
    "of the gradients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use new graph for this section to keep things tidy.\n",
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.907995876116&quot;).pbtxt = 'node {\\n  name: &quot;a&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;b&quot;\\n  input: &quot;b/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;a_times_b&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;a&quot;\\n  input: &quot;b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;a_times_b&quot;\\n  input: &quot;mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;sub&quot;\\n  input: &quot;pow/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;pow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.907995876116&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define our calculation + loss.\n",
    "\n",
    "with graph.as_default():\n",
    "    a = tf.placeholder(shape=(), dtype=tf.float32, name='a')\n",
    "    b = tf.Variable(0.0, name='b')\n",
    "    a_times_b = tf.placeholder(shape=(), dtype=tf.float32, name='a_times_b')\n",
    "    # Use overloaded Python operators for convenience.\n",
    "    # (this will translate to tf.mul(), tf.sub(), and tf.pow())\n",
    "    loss = (a_times_b - a * b) ** 2\n",
    "    # Let's use the identity Op to add a name to the \"loss\" tensor.\n",
    "    loss = tf.identity(loss, name='loss')\n",
    "\n",
    "    show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.481115368439&quot;).pbtxt = 'node {\\n  name: &quot;a&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;b&quot;\\n  input: &quot;b/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;a_times_b&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;a&quot;\\n  input: &quot;b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;a_times_b&quot;\\n  input: &quot;mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;sub&quot;\\n  input: &quot;pow/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;pow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/pow_grad/Shape&quot;\\n  input: &quot;gradients/pow_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;pow/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/sub/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;pow/y&quot;\\n  input: &quot;gradients/pow_grad/sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/Pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;sub&quot;\\n  input: &quot;gradients/pow_grad/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/pow_grad/mul&quot;\\n  input: &quot;gradients/pow_grad/Pow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/pow_grad/mul_1&quot;\\n  input: &quot;gradients/pow_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/pow_grad/Sum&quot;\\n  input: &quot;gradients/pow_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/Greater/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/Greater&quot;\\n  op: &quot;Greater&quot;\\n  input: &quot;sub&quot;\\n  input: &quot;gradients/pow_grad/Greater/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;gradients/pow_grad/Greater&quot;\\n  input: &quot;gradients/pow_grad/Log&quot;\\n  input: &quot;gradients/pow_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;pow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/mul_3&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/pow_grad/mul_2&quot;\\n  input: &quot;gradients/pow_grad/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/pow_grad/mul_3&quot;\\n  input: &quot;gradients/pow_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/pow_grad/Sum_1&quot;\\n  input: &quot;gradients/pow_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/pow_grad/Reshape&quot;\\n  input: &quot;^gradients/pow_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/pow_grad/Reshape&quot;\\n  input: &quot;^gradients/pow_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/pow_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/pow_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/pow_grad/Reshape_1&quot;\\n  input: &quot;^gradients/pow_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/pow_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/pow_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Sum&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/pow_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Neg&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/mul_grad/Shape&quot;\\n  input: &quot;gradients/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/mul&quot;\\n  input: &quot;gradients/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/mul_grad/Sum&quot;\\n  input: &quot;gradients/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;a&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/mul_1&quot;\\n  input: &quot;gradients/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_b/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;b&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_b/ApplyGradientDescent&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.481115368439&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Magic happens : add optimizer.\n",
    "\n",
    "with graph.as_default():\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "    # We can now minimize the loss by calling this train_op (many times),\n",
    "    # which will change the value of \"b\" upon every invocation a bit in such\n",
    "    # a way that the loss becomes smaller.\n",
    "    train_op = optimizer.minimize(loss)\n",
    "\n",
    "    show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b= [0.0]\n",
      "b= [16.800001]\n",
      "b= [20.16]\n",
      "b= [20.832001]\n",
      "b= [20.9664]\n",
      "b= [20.99328]\n",
      "b= [20.998655]\n",
      "b= [20.999731]\n",
      "b= [20.999947]\n",
      "b= [20.999989]\n",
      "b= [20.999998]\n"
     ]
    }
   ],
   "source": [
    "# Do the computation.\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Variables must be initialized before first use.\n",
    "    tf.global_variables_initializer().run()\n",
    "    # Feed the same result at every step.\n",
    "    feed_dict = {a: 2, a_times_b: 42}\n",
    "\n",
    "    print 'b=', sess.run([b])\n",
    "    for i in range(10):\n",
    "        # Update b by calling train_op.\n",
    "        sess.run([train_op], feed_dict=feed_dict)\n",
    "        # Print our updated guess for b.\n",
    "        print 'b=', sess.run([b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Neural function approximator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can be seen as generic function approximators\n",
    "`y = f(x)` -- in this section we will use a network to approximate\n",
    "a simple mathematical function with a scalar input.\n",
    "\n",
    "The same approach can be used to train arbitrary function (for example\n",
    "a function where `x` is a dense vector of a megapixel image, and `y` is\n",
    "a probability distribution over thousands of different object classes).\n",
    "\n",
    "A crucial part when designing such a network is a good choice of\n",
    "\"hyperparameters\" that define *how* the network should be created and\n",
    "trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class for function approximation. Defining all the code\n",
    "# in a single class makes it easier to instantiate different\n",
    "# \"versions\" of the approximator (to approximate different functions\n",
    "# with different configurations).\n",
    "\n",
    "class FunctionApproximator(object):\n",
    "    \"\"\"A class for function approximation using Tensorflow.\n",
    "\n",
    "    This class implements both building the graph and updating the\n",
    "    variables to better approximate the target function, so that it\n",
    "    can be instantiated with different functions/configurations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, f, hidden_layers):\n",
    "        \"\"\"Initializes a new function approximator.\n",
    "        \n",
    "        Args:\n",
    "          f: Scalar Python functional that should be approximated.\n",
    "            Signature: f(x:Number) -> Number\n",
    "          hidden_layers: Iterable specifying number of units per layer.\n",
    "        \"\"\"\n",
    "        self.f = f\n",
    "        self.hidden_layers = hidden_layers\n",
    "        # Initialize new graph that only contains Ops needed for\n",
    "        # function approximation.\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self._build()\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        \"\"\"Initializes weights.\"\"\"\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "        self.init_op.run(session=self.sess)\n",
    "\n",
    "    def _build(self):\n",
    "        # The values for \"x\" and \"y\" are provided during training.\n",
    "        # Note the dynamic first dimension (=number of samples in batch).\n",
    "        self.x = tf.placeholder(shape=(None,), dtype=tf.float32)\n",
    "        self.y = tf.placeholder(shape=(None,), dtype=tf.float32)\n",
    "        # Reshape e.g. [1, 2, 3] to [[1], [2], [3]] because this latter\n",
    "        # shape is required by tf.layers() below.\n",
    "        x = tf.reshape(self.x, (-1, 1))\n",
    "        for units in self.hidden_layers:\n",
    "            # We use tf.layers() helper function to create \"fully connected\n",
    "            # layers\" where every neuron is connected to every neuron in the\n",
    "            # previous layer. This helper function takes care of defining\n",
    "            # variables and initializing them.\n",
    "            x = tf.layers.dense(inputs=x, units=units, activation=tf.nn.relu)\n",
    "        # Our predicted \"y\".\n",
    "        self.y_ = tf.layers.dense(inputs=x, units=1, activation=None)\n",
    "        # Reshape e.g. [[1], [2], [3]] (by tf.layers()) to [1, 2, 3].\n",
    "        self.y_ = tf.reshape(self.y_, (-1,))\n",
    "\n",
    "        # Compute loss.\n",
    "        self.loss = tf.reduce_mean((self.y - self.y_)**2)\n",
    "        # Add Ops for minimizing loss.\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "        self.train_op = optimizer.minimize(self.loss)\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "\n",
    "    def fit(self, x_min, x_max, steps, batch_size, show_progress=False):\n",
    "        \"\"\"Fits the weights to better approximate the function.\n",
    "\n",
    "        This function will generate random samples \"x\" within [x_min, x_max]\n",
    "        and update the network's weight to better approximate y=f(x).\n",
    "\n",
    "        Args:\n",
    "          x_min: Lower bound for generation of \"x\".\n",
    "          x_max: Upper bound for generation of \"x\".\n",
    "          steps: Number of training steps.\n",
    "          batch_size: Number of samples to train network with in every step.\n",
    "        \"\"\"\n",
    "        t0 = time.time()\n",
    "\n",
    "        losses = []\n",
    "        for step in range(steps):\n",
    "            # Generate samples.\n",
    "            x_data = np.random.uniform(low=x_min, high=x_max, size=batch_size)\n",
    "            y_data = self.f(x_data)\n",
    "            feed_dict = {\n",
    "                self.x: x_data,\n",
    "                self.y: y_data\n",
    "            }\n",
    "            # Update the weights and get the loss.\n",
    "            loss_data, _ = self.sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n",
    "            losses.append(loss_data)\n",
    "            if show_progress and step % (steps // 10) == 0:\n",
    "                print 'step=%6d loss=%f' % (step, loss_data)\n",
    "\n",
    "        dt = time.time() - t0\n",
    "        return losses, dt\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        \"\"\"Computes approximated function values.\"\"\"\n",
    "        return self.sess.run([self.y_], {self.x: x_data})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=     0 loss=0.615165\n",
      "step=  1000 loss=0.021150\n",
      "step=  2000 loss=0.005446\n",
      "step=  3000 loss=0.001960\n",
      "step=  4000 loss=0.000976\n",
      "step=  5000 loss=0.000472\n",
      "step=  6000 loss=0.000363\n",
      "step=  7000 loss=0.000211\n",
      "step=  8000 loss=0.000172\n",
      "step=  9000 loss=0.000112\n",
      "31.89 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f78c65729d0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78c64b70d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \"hidden_layers\" specifies the number of neurons per layer.\n",
    "# The network will be trained with batch_size x \"steps\" random datapoints.\n",
    "\n",
    "### YOUR ACTION REQUIRED:\n",
    "# Try to achieve a good function approximation by finding good parameters...\n",
    "hidden_layers, steps = [100, 50], 10000 #hidden_layers, steps = [5, 5, 5, 5, 5], 1000\n",
    "\n",
    "tf_sin = FunctionApproximator(f=np.sin, hidden_layers=hidden_layers)\n",
    "\n",
    "# Train the network.\n",
    "losses, dt = tf_sin.fit(x_min=-3., x_max=3., steps=steps, batch_size=1000,\n",
    "                        show_progress=True)\n",
    "print '%.2f seconds' % dt\n",
    "\n",
    "# Visualize some predictions\n",
    "x_data = np.random.uniform(low=-3., high=3., size=100)\n",
    "x_data.sort()\n",
    "y_data = np.sin(x_data)\n",
    "y_predictions = tf_sin.predict(x_data)\n",
    "\n",
    "pyplot.scatter(x_data, y_data)\n",
    "pyplot.plot(x_data, y_predictions, 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A References\n",
    "\n",
    "Unfortunately, we don't have time to talk about more ML in this\n",
    "workshop. Two good online references:\n",
    "\n",
    "- http://deeplearningbook.org (by Ian Goodfellow et al) – more theoretical\n",
    "- http://neuralnetworksanddeeplearning.com/ (by Michael Nielson) – more hands-on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
