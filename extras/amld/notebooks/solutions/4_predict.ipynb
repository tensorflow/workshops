{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_predict","provenance":[],"collapsed_sections":[],"last_runtime":{"build_target":"//commerce/dataquality/attribute/colab/kernel:notebook","kind":"private"},"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8kdLZ_zGPQgv","colab_type":"text"},"source":["# Making predictions"]},{"cell_type":"markdown","metadata":{"id":"41RIQs90f7pK","colab_type":"text"},"source":["## Load Model"]},{"cell_type":"markdown","metadata":{"id":"vYruXX9GIGq3","colab_type":"text"},"source":["This notebook loads a model previously trained in [2_keras.ipynb](https://github.com/tensorflow/workshops/tree/master/extras/amld/notebooks/solutions/2_keras.ipynb) or [3_eager.ipynb](https://github.com/tensorflow/workshops/tree/master/extras/amld/notebooks/solutions/3_eager.ipynb) from earlier in the TensorFlow Basics workshop.\n","\n","**Note** : The code in this notebook is quite Colab specific and won't work with Jupyter."]},{"cell_type":"code","metadata":{"id":"jHGIMZC5-JSR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d9fe0624-fac9-4bb2-92c6-5a7d0160f333","executionInfo":{"status":"ok","timestamp":1582839638073,"user_tz":-60,"elapsed":840,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["# In Jupyter, you would need to install TF 2 via !pip.\n","%tensorflow_version 2.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UwtuKp3z-eqE","colab_type":"code","colab":{}},"source":["## Load models from Drive (Colab only).\n","models_path = '/content/gdrive/My Drive/amld_data/models'\n","data_path = '/content/gdrive/My Drive/amld_data/zoo_img'\n","\n","## Or load models from local machine.\n","# models_path = './amld_models'\n","# data_path = './amld_data'\n","## Or load models from GCS (Colab only).\n","# models_path = 'gs://amld-datasets/models'\n","# data_path = 'gs://amld-datasets/zoo_img_small'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"itNiEr6rUXYa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"outputId":"9d3e43b6-e5d5-4258-9a79-633ed97bd3e5","executionInfo":{"status":"ok","timestamp":1582839331516,"user_tz":-60,"elapsed":27784,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["if models_path.startswith('/content/gdrive/'):\n","  from google.colab import drive\n","  drive.mount('/content/gdrive')\n","\n","if models_path.startswith('gs://'):\n","  # Keras doesn't read directly from GCS -> download.\n","  from google.colab import auth\n","  import os\n","  os.makedirs('./amld_models', exist_ok=True)\n","  auth.authenticate_user()\n","  !gsutil cp -r \"$models_path\"/\\* ./amld_models\n","  models_path = './amld_models'\n","\n","!ls -lh \"$models_path\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","ls: cannot access '/content/gdrive/My Drive/amld_data/models': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BgTZXXvsH5p4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b3e2f832-0cc6-49b9-c341-5b4f5e0dbca6","executionInfo":{"status":"ok","timestamp":1582839340365,"user_tz":-60,"elapsed":36628,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["import json, os\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import tensorflow as tf\n","\n","# Tested with TensorFlow 2.1.0\n","print('version={}, CUDA={}, GPU={}, TPU={}'.format(\n","    tf.__version__, tf.test.is_built_with_cuda(),\n","    # GPU attached? Note that you can \"Runtime/Change runtime type...\" in Colab.\n","    len(tf.config.list_physical_devices('GPU')) > 0,\n","    # TPU accessible? (only works on Colab)\n","    'COLAB_TPU_ADDR' in os.environ))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["version=2.1.0, CUDA=True, GPU=True, TPU=False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mID7nXzKnQiG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":212},"outputId":"86297dee-a085-48be-be39-a1025a9cc484","executionInfo":{"status":"ok","timestamp":1582839341471,"user_tz":-60,"elapsed":37728,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["# Load the label names from the dataset.\n","labels = [label.strip() for label in \n","          tf.io.gfile.GFile('{}/labels.txt'.format(data_path))]\n","print('\\n'.join(['%2d: %s' % (i, label) for i, label in enumerate(labels)]))"],"execution_count":5,"outputs":[{"output_type":"stream","text":[" 0: camel\n"," 1: crocodile\n"," 2: dolphin\n"," 3: elephant\n"," 4: flamingo\n"," 5: giraffe\n"," 6: kangaroo\n"," 7: lion\n"," 8: monkey\n"," 9: penguin\n","10: rhinoceros\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j0FJtTGNl5MN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":230},"outputId":"7f3da460-49ae-47c4-baf6-9899de5bcb30","executionInfo":{"status":"ok","timestamp":1582839350818,"user_tz":-60,"elapsed":47070,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["# Load model from 2_keras.ipynb\n","model = tf.keras.models.load_model(os.path.join(models_path, 'linear.h5'))\n","model.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten (Flatten)            (None, 4096)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 11)                45067     \n","=================================================================\n","Total params: 45,067\n","Trainable params: 45,067\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RTMWbsiof92f","colab_type":"text"},"source":["## Live Predictions"]},{"cell_type":"code","metadata":{"id":"_DgpN1tGdPfc","colab_type":"code","colab":{}},"source":["from google.colab import output\n","import IPython\n","\n","def predict(img_64):\n","  \"\"\"Get Predictions for provided image.\n","  \n","  Args:\n","    img_64: Raw image data (dtype int).\n","\n","  Returns:\n","    A JSON object with the value for `result` being a text representation of the\n","    top predictions.\n","  \"\"\"\n","  # Reshape image into batch with single image (extra dimension \"1\").\n","  preds = model.predict(np.array(img_64, float).reshape([1, 64, 64]))\n","  # Get top three predictions (reverse argsort).\n","  top3 = (-preds[0]).argsort()[:3]\n","  # Return both probability and prediction label name.\n","  result = '\\n'.join(['%.3f: %s' % (preds[0, i], labels[i]) for i in top3])\n","  return IPython.display.JSON(dict(result=result))\n","\n","output.register_callback('amld.predict', predict)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OoPSNCE_4r7p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":296},"outputId":"fa980b67-490f-42e8-c94e-9aca896ccbf1","executionInfo":{"status":"ok","timestamp":1582839350819,"user_tz":-60,"elapsed":47067,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["%%html\n","<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, user-scalable=no\">\n","<canvas width=\"256\" height=\"256\" id=\"canvas\" style=\"border:1px solid black\"></canvas><br />\n","<button id=\"clear\">clear</button><br />\n","<pre id=\"output\"></pre>\n","<script>\n","  let upscaleFactor = 4, halfPenSize = 2\n","  let canvas = document.getElementById('canvas')\n","  let output = document.getElementById('output')\n","  let ctx = canvas.getContext('2d')\n","  let img_64 = new Uint8Array(64*64)\n","  let dragging = false\n","  let timeout\n","  let predict = () => {\n","    google.colab.kernel.invokeFunction('amld.predict', [Array.from(img_64)], {}).then(\n","        obj => output.textContent = obj.data['application/json'].result)\n","  }\n","  const getPos = e => {\n","    let x = e.offsetX, y = e.offsetY\n","    if (e.touches) {\n","      const rect = canvas.getBoundingClientRect()\n","      x = e.touches[0].clientX - rect.left\n","      y = e.touches[0].clientY - rect.left\n","    }\n","    return {\n","      x: Math.floor((x - 2*halfPenSize*upscaleFactor/2)/upscaleFactor),\n","      y: Math.floor((y - 2*halfPenSize*upscaleFactor/2)/upscaleFactor),\n","    }\n","  }\n","  const handler = e => {\n","    const { x, y } = getPos(e)\n","    ctx.fillStyle = 'black'\n","    ctx.fillRect(x*upscaleFactor, y*upscaleFactor,\n","                 2*halfPenSize*upscaleFactor, 2*halfPenSize*upscaleFactor)\n","    for (let yy = y - halfPenSize; yy < y + halfPenSize; yy++)\n","      for (let xx = x - halfPenSize; xx < x + halfPenSize; xx++)\n","        img_64[64*Math.min(63, Math.max(0, yy)) + Math.min(63, Math.max(0, xx))] = 1\n","    clearTimeout(timeout)\n","    timeout = setTimeout(predict, 500)\n","  }\n","  canvas.addEventListener('touchstart', e => {dragging=true; handler(e)})\n","  canvas.addEventListener('touchmove', e => {e.preventDefault(); dragging && handler(e)})\n","  canvas.addEventListener('touchend', () => dragging=false)\n","  canvas.addEventListener('mousedown', e => {dragging=true; handler(e)})\n","  canvas.addEventListener('mousemove', e => {dragging && handler(e)})\n","  canvas.addEventListener('mouseup', () => dragging=false)\n","  canvas.addEventListener('mouseleave', () => dragging=false)\n","  document.getElementById('clear').addEventListener('click', () => {\n","    ctx.fillStyle = 'white'\n","    ctx.fillRect(0, 0, 64*upscaleFactor, 64*upscaleFactor)\n","    output.textContent = ''\n","    img_64 = new Uint8Array(64*64)\n","  })\n","</script>"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/html":["<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, user-scalable=no\">\n","<canvas width=\"256\" height=\"256\" id=\"canvas\" style=\"border:1px solid black\"></canvas><br />\n","<button id=\"clear\">clear</button><br />\n","<pre id=\"output\"></pre>\n","<script>\n","  let upscaleFactor = 4, halfPenSize = 2\n","  let canvas = document.getElementById('canvas')\n","  let output = document.getElementById('output')\n","  let ctx = canvas.getContext('2d')\n","  let img_64 = new Uint8Array(64*64)\n","  let dragging = false\n","  let timeout\n","  let predict = () => {\n","    google.colab.kernel.invokeFunction('amld.predict', [Array.from(img_64)], {}).then(\n","        obj => output.textContent = obj.data['application/json'].result)\n","  }\n","  const getPos = e => {\n","    let x = e.offsetX, y = e.offsetY\n","    if (e.touches) {\n","      const rect = canvas.getBoundingClientRect()\n","      x = e.touches[0].clientX - rect.left\n","      y = e.touches[0].clientY - rect.left\n","    }\n","    return {\n","      x: Math.floor((x - 2*halfPenSize*upscaleFactor/2)/upscaleFactor),\n","      y: Math.floor((y - 2*halfPenSize*upscaleFactor/2)/upscaleFactor),\n","    }\n","  }\n","  const handler = e => {\n","    const { x, y } = getPos(e)\n","    ctx.fillStyle = 'black'\n","    ctx.fillRect(x*upscaleFactor, y*upscaleFactor,\n","                 2*halfPenSize*upscaleFactor, 2*halfPenSize*upscaleFactor)\n","    for (let yy = y - halfPenSize; yy < y + halfPenSize; yy++)\n","      for (let xx = x - halfPenSize; xx < x + halfPenSize; xx++)\n","        img_64[64*Math.min(63, Math.max(0, yy)) + Math.min(63, Math.max(0, xx))] = 1\n","    clearTimeout(timeout)\n","    timeout = setTimeout(predict, 500)\n","  }\n","  canvas.addEventListener('touchstart', e => {dragging=true; handler(e)})\n","  canvas.addEventListener('touchmove', e => {e.preventDefault(); dragging && handler(e)})\n","  canvas.addEventListener('touchend', () => dragging=false)\n","  canvas.addEventListener('mousedown', e => {dragging=true; handler(e)})\n","  canvas.addEventListener('mousemove', e => {dragging && handler(e)})\n","  canvas.addEventListener('mouseup', () => dragging=false)\n","  canvas.addEventListener('mouseleave', () => dragging=false)\n","  document.getElementById('clear').addEventListener('click', () => {\n","    ctx.fillStyle = 'white'\n","    ctx.fillRect(0, 0, 64*upscaleFactor, 64*upscaleFactor)\n","    output.textContent = ''\n","    img_64 = new Uint8Array(64*64)\n","  })\n","</script>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"LJQwqA5TUhlL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":514},"outputId":"9d0a545a-7c48-4e93-addd-9c0c64916189","executionInfo":{"status":"ok","timestamp":1582839354653,"user_tz":-60,"elapsed":50899,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["# YOUR ACTION REQUIRED:\n","# Load another model from 2_keras.ipynb and observe:\n","# - Do you get better/worse predictions?\n","# - Do you feel a difference in latency?\n","# - Can you figure out by how the model \"thinks\" by providing similar images\n","#   that yield different predictions, or different images that yield the same\n","#   picture?\n","#--snip\n","model = tf.keras.models.load_model(os.path.join(models_path, 'conv.h5'))\n","model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","reshape (Reshape)            (None, 64, 64, 1)         0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 64, 64, 32)        3232      \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 64, 64, 32)        102432    \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 16, 16, 64)        51264     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               262400    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 11)                2827      \n","=================================================================\n","Total params: 422,155\n","Trainable params: 422,155\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xm3XfMvkgFKO","colab_type":"text"},"source":["## TensorFlow.js\n","\n","\n","Read about basic concepts in TensorFlow.js:\n","https://js.tensorflow.org/tutorials/core-concepts.html\n","\n","If you find the Colab `%%html` way cumbersome to explore the JS API, then have a try codepen by clicking on the \"Try TensorFlow.js\" button on https://js.tensorflow.org/"]},{"cell_type":"markdown","metadata":{"id":"VogZyTDRZwQn","colab_type":"text"},"source":["### Basics"]},{"cell_type":"code","metadata":{"id":"Qp8mXdaBy2rC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":100},"outputId":"00aa0dbf-36ac-44d8-b800-f85eac92d125","executionInfo":{"status":"ok","timestamp":1582839354654,"user_tz":-60,"elapsed":50898,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["# Getting the data of a tensor in TensorFlow.js: Use the async .data() method\n","# to show the output in the \"output\" element.\n","# See output in javascript console (e.g. Chrome developer tools).\n","# For convenience, you can also use the following Codepen:\n","# https://codepen.io/amld-tensorflow-basics/pen/OJPagyN\n","%%html\n","<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js\"></script>\n","<pre id=\"output\"></pre>\n","<script>\n","  let output = document.getElementById('output')\n","  let t = tf.tensor([1, 2, 3])\n","  output.textContent = t\n","  // YOUR ACTION REQUIRED:\n","  // Use \"t.data()\" to append the tensor's data values to \"output.textContent\".\n","  //--snip\n","  t.data().then(t_data => t_data.forEach(\n","    (value, idx) => output.textContent += `\\n${idx}: ${value}`\n","  ))"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/html":["<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js\"></script>\n","<pre id=\"output\"></pre>\n","<script>\n","  let output = document.getElementById('output')\n","  let t = tf.tensor([1, 2, 3])\n","  output.textContent = t\n","  // YOUR ACTION REQUIRED:\n","  // Use \"t.data()\" to append the tensor's data values to \"output.textContent\".\n","  //--snip\n","  t.data().then(t_data => t_data.forEach(\n","    (value, idx) => output.textContent += `\\n${idx}: ${value}`\n","  ))"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"_-KQ05ww6zCY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"1f739c74-d73d-4e0c-fb67-e5aa7aacedd3","executionInfo":{"status":"ok","timestamp":1582839354654,"user_tz":-60,"elapsed":50896,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["# Get top 3 predictions using TensorFlow Eager.\n","preds = tf.constant([0.1, 0.5, 0.2, 0.0])\n","topk = tf.math.top_k(preds, 3)\n","for idx, value in zip(topk.indices.numpy(), topk.values.numpy()):\n","  print('idx', idx, 'value', value)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["idx 1 value 0.5\n","idx 2 value 0.2\n","idx 0 value 0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6tUk3AAl7qG1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66},"outputId":"3c04e8c0-6fd5-443b-ae2d-d553e63cda03","executionInfo":{"status":"ok","timestamp":1582839354655,"user_tz":-60,"elapsed":50895,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["# Implement the same top 3 functionality in TensorFlow.js, showing the output\n","# in the \"output\" element.\n","# See https://js.tensorflow.org/api/latest/index.html#topk\n","%%html\n","<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js\"></script>\n","<pre id=\"output\"></pre>\n","<script>\n","  let output = document.getElementById('output')\n","  let preds = tf.tensor([0.1, 0.5, 0.2, 0.0])\n","  // YOUR ACTION REQUIRED:\n","  // Use tf.topk() to get top 3 predictions in \"preds\" and append both the\n","  // index and the value of these predictions to \"output\".\n","  //--snip\n","  const { indices, values } = tf.topk(preds, 3)\n","  Promise.all([indices.data(), values.data()]).then(indices_values => {\n","    const [ indices, values ] = indices_values\n","    indices.forEach((idx, i) =>  {\n","      output.textContent += `idx ${idx} value ${values[i]}\\n`\n","    })\n","  })"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/html":["<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js\"></script>\n","<pre id=\"output\"></pre>\n","<script>\n","  let output = document.getElementById('output')\n","  let preds = tf.tensor([0.1, 0.5, 0.2, 0.0])\n","  // YOUR ACTION REQUIRED:\n","  // Use tf.topk() to get top 3 predictions in \"preds\" and append both the\n","  // index and the value of these predictions to \"output\".\n","  //--snip\n","  const { indices, values } = tf.topk(preds, 3)\n","  Promise.all([indices.data(), values.data()]).then(indices_values => {\n","    const [ indices, values ] = indices_values\n","    indices.forEach((idx, i) =>  {\n","      output.textContent += `idx ${idx} value ${values[i]}\\n`\n","    })\n","  })"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"OiROzUvkZyrl","colab_type":"text"},"source":["### Convert Model\n","\n","We can convert the Keras model into TensorFlow.js format using the Python package `tensorflowjs`.\n","\n","Read more about importing Keras models:\n","https://js.tensorflow.org/tutorials/import-keras.html\n"]},{"cell_type":"code","metadata":{"id":"X0XOZ-gWksii","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":176},"outputId":"6f15e021-4edb-4b77-c74b-1c0b4178bdce","executionInfo":{"status":"ok","timestamp":1582839377112,"user_tz":-60,"elapsed":73350,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["# (Never mind the incompatible package complaints - it just works fine.)\n","!pip install -q tensorflowjs"],"execution_count":13,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 61kB 4.8MB/s \n","\u001b[K     |████████████████████████████████| 104.6MB 50kB/s \n","\u001b[K     |████████████████████████████████| 256kB 57.6MB/s \n","\u001b[K     |████████████████████████████████| 901kB 52.4MB/s \n","\u001b[?25h  Building wheel for PyInquirer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.7.2, but you'll have google-auth 1.11.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sdWRdec1aNUq","colab_type":"code","colab":{}},"source":["# Specify directory where to store model.\n","tfjs_model_path = './tfjs/model'\n","!mkdir -p \"$tfjs_model_path\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d9ljzuvLg1bJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"d14ba958-c5c6-4c68-d0ba-405bbcf8e31d","executionInfo":{"status":"ok","timestamp":1582839380445,"user_tz":-60,"elapsed":76672,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["import tensorflowjs as tfjs\n","# Convert model\n","tf.keras.backend.clear_session()  # Clean up variable names before exporting.\n","# (You can safely ignore the H5pyDeprecationWarning here...)\n","model = tf.keras.models.load_model(os.path.join(models_path, 'linear.h5'))\n","tfjs.converters.save_keras_model(model, tfjs_model_path)\n","!ls -lh \"$tfjs_model_path\""],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/keras_h5_conversion.py:122: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n","  return h5py.File(h5file)\n"],"name":"stderr"},{"output_type":"stream","text":["total 184K\n","-rw-r--r-- 1 root root 177K Feb 27 21:36 group1-shard1of1.bin\n","-rw-r--r-- 1 root root 1.5K Feb 27 21:36 model.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cdQpxNKVgQNz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f3dd4123-fdac-46de-ae5a-202f1f2ec4ca","executionInfo":{"status":"ok","timestamp":1582839380445,"user_tz":-60,"elapsed":76667,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["import json\n","# You can copy this into the JavaScript code in the next cell if you load a\n","# model trained on a custom dataset (code below assumes dataset=\"zoo\").\n","print(json.dumps(labels))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[\"camel\", \"crocodile\", \"dolphin\", \"elephant\", \"flamingo\", \"giraffe\", \"kangaroo\", \"lion\", \"monkey\", \"penguin\", \"rhinoceros\"]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RROyvNaPalea","colab_type":"text"},"source":["### Predict in JS"]},{"cell_type":"markdown","metadata":{"id":"yK3ZcgRxasGv","colab_type":"text"},"source":["**1. write `index.html`**\n","\n","This is essentially the same drawing code as above in \"Live Predictions\", additionally some code to load the exported Javascript model for calling `model.predict()`."]},{"cell_type":"code","metadata":{"id":"m12iXwlzaglF","colab_type":"code","colab":{}},"source":["with open('./tfjs/index.html', 'w') as f:\n","  f.write('''\n","<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, user-scalable=no\">\n","<canvas width=\"256\" height=\"256\" id=\"canvas\" style=\"border:1px solid black\"></canvas><br />\n","<button id=\"clear\">clear</button><br />\n","<pre id=\"output\"></pre>\n","<script>\n","  let upscaleFactor = 4, halfPenSize = 2\n","  let canvas = document.getElementById('canvas')\n","  let output = document.getElementById('output')\n","  let ctx = canvas.getContext('2d')\n","  let img_64 = new Uint8Array(64*64)\n","  let dragging = false\n","  let timeout\n","  let predict = () => {\n","    google.colab.kernel.invokeFunction('amld.predict', [Array.from(img_64)], {}).then(\n","        obj => output.textContent = obj.data['application/json'].result)\n","  }\n","  const getPos = e => {\n","    let x = e.offsetX, y = e.offsetY\n","    if (e.touches) {\n","      const rect = canvas.getBoundingClientRect()\n","      x = e.touches[0].clientX - rect.left\n","      y = e.touches[0].clientY - rect.left\n","    }\n","    return {\n","      x: Math.floor((x - 2*halfPenSize*upscaleFactor/2)/upscaleFactor),\n","      y: Math.floor((y - 2*halfPenSize*upscaleFactor/2)/upscaleFactor),\n","    }\n","  }\n","  const handler = e => {\n","    const { x, y } = getPos(e)\n","    ctx.fillStyle = 'black'\n","    ctx.fillRect(x*upscaleFactor, y*upscaleFactor,\n","                 2*halfPenSize*upscaleFactor, 2*halfPenSize*upscaleFactor)\n","    for (let yy = y - halfPenSize; yy < y + halfPenSize; yy++)\n","      for (let xx = x - halfPenSize; xx < x + halfPenSize; xx++)\n","        img_64[64*Math.min(63, Math.max(0, yy)) + Math.min(63, Math.max(0, xx))] = 1\n","    clearTimeout(timeout)\n","    timeout = setTimeout(predict, 500)\n","  }\n","  canvas.addEventListener('touchstart', e => {dragging=true; handler(e)})\n","  canvas.addEventListener('touchmove', e => {e.preventDefault(); dragging && handler(e)})\n","  canvas.addEventListener('touchend', () => dragging=false)\n","  canvas.addEventListener('mousedown', e => {dragging=true; handler(e)})\n","  canvas.addEventListener('mousemove', e => {dragging && handler(e)})\n","  canvas.addEventListener('mouseup', () => dragging=false)\n","  canvas.addEventListener('mouseleave', () => dragging=false)\n","  document.getElementById('clear').addEventListener('click', () => {\n","    ctx.fillStyle = 'white'\n","    ctx.fillRect(0, 0, 64*upscaleFactor, 64*upscaleFactor)\n","    output.textContent = ''\n","    img_64 = new Uint8Array(64*64)\n","  })\n","</script>\n","<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js\"></script>\n","<script>\n","  const labels = %s\n","  const modelPath = './model/model.json'\n","  let model = null\n","  tf.loadLayersModel(modelPath)\n","    .then(response => model = response)\n","    .catch(error => output.textContent = 'ERROR : ' + error.message)\n","\n","  predict = () => {\n","    const preds = model.predict(tf.tensor(img_64).reshape([1, 64, -1]))\n","    const { values, indices } = tf.topk(preds, 3)\n","    Promise.all([values.data(), indices.data()]).then(data => {\n","      const [ values, indices ] = data\n","      output.textContent = ''\n","      values.forEach((v, i) => output.textContent +=  `${labels[indices[i]]} : ${v.toFixed(3)}\\n`)\n","    })\n","  }\n","</script>''' % json.dumps(labels))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4fXMdkklwOTL","colab_type":"text"},"source":["**2. A static web server**\n","\n","Serving both `index.html` and the converted model."]},{"cell_type":"code","metadata":{"id":"tdkyGPmvZf4K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":247},"outputId":"e8bf1eb9-09fa-4bb1-98ca-a75efb95c96f","executionInfo":{"status":"ok","timestamp":1582839383728,"user_tz":-60,"elapsed":79939,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["# Download ngrok for tunneling.\n","!if [ ! -f ./ngrok ]; then \\\n"," wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip; \\\n"," unzip -o ngrok-stable-linux-amd64.zip; \\\n"," fi"],"execution_count":18,"outputs":[{"output_type":"stream","text":["--2020-02-27 21:36:21--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.227.168.133, 52.20.185.228, 3.223.119.4, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.227.168.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  14.0MB/s    in 0.9s    \n","\n","2020-02-27 21:36:23 (14.0 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0pXBsA5tZf6U","colab_type":"code","colab":{}},"source":["# Then start a mini web server at a random port.\n","import random\n","port = random.randint(1000, 2**16)\n","\n","!pkill ngrok\n","!kill $(ps x | grep -v grep | grep http.server | awk '{print $1}') 2>/dev/null\n","\n","get_ipython().system_raw(\n","    'cd ./tfjs && python3 -m http.server {} &'\n","    .format(port)\n",")\n","\n","# And, forward the port using ngrok.\n","get_ipython().system_raw('./ngrok http {} &'.format(port))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8OpgcVubwWdx","colab_type":"text"},"source":["**3. Port forwarding**\n","\n","Via a `ngrok` tunnel from the local machine to the internet."]},{"cell_type":"code","metadata":{"id":"rcOW2pxypAqh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"be93b1da-3b49-491f-be50-49a34038ec48","executionInfo":{"status":"ok","timestamp":1582839388157,"user_tz":-60,"elapsed":84359,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["# Get the public address from localhost:4040 (ngrok's web interface).\n","import time, urllib\n","time.sleep(1)  # Give ngrok time to startup.\n","ngrok_data = json.load(\n","    urllib.request.urlopen('http://localhost:4040/api/tunnels'))\n","ngrok_data['tunnels'][0]['public_url']"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'https://a93a0083.ngrok.io'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"Ug9gk1oma-64","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":346},"outputId":"490dfce2-1fdb-44de-d9b4-beca0ebb65a7","executionInfo":{"status":"ok","timestamp":1582839391573,"user_tz":-60,"elapsed":87773,"user":{"displayName":"Andreas Steiner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64","userId":"08860260976100898876"}}},"source":["# You can connect to this external address using your mobile phone!\n","# Once the page is loaded you can turn on flight modus and verify that\n","# predictions are really generated on-device. :-)\n","!pip install -q qrcode\n","import qrcode\n","qrcode.make(ngrok_data['tunnels'][0]['public_url'])"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUoAAAFKAQAAAABTUiuoAAAB+0lEQVR4nO2bQarjMAyGP40NXbrw\nDtCjODcb5mb2UeYAA/GyEKNZ2G7awoP2QV4yjLQIcfItfhCSJTkR5UXLP14lwVBDDTXUUEO3RKWb\n73dT8UAZj6fNBRj6DhpVVXUGTTglnwFwqqqqj+g2Agx9By09hGSiiqbxWkT89wgw9AuoJpzKRJWd\nBBj6HloFmst2EmDoZzbyXFCggEQF8tQf3/fOu2s1tHsrt8TngPKxSJw/gKd0uLtWQ5u31hDSfHYo\npYo+RtYBtBra+61bgwXhKjKFBVpsFY9Mmwsw9A20l+xBVX7+PikUD1lOSr5c5QHdRoChL9nYtyaH\ngFuUAkoBIcwInFQOotVQ+rQiLGgKem8pjEtb7q7V0O6tqAvEeUyeoqpquntr3joE2mvCVsEHHf3W\n+Y8fBWEdLdnuWg0dmbCZa6mvhVpbrqG2u1ZD6bvSDJpCT4fE2elaJ9q+dRS0pTkhLB6KR/PZLUIY\ndXtMdeTE3bUaOmJrWA+rsLQzr/VisXUYdD07hnAV4q1F/iYBhr6DrmfHv+Q2ahrjp76DHUWrobez\nY8ApUIUsYjP4w6NVyJc+xrhPh0fU+p+h/mktUavX1hOH6smXxUtM2wkw9AveGmfHmsX1ij2mCjFh\n3zwdBn2eZYySfRktcrAK/jio2F8LhhpqqKGG/kPoX1byK63MpLJWAAAAAElFTkSuQmCC\n","text/plain":["<qrcode.image.pil.PilImage at 0x7fa9168bb668>"]},"metadata":{"tags":[]},"execution_count":21}]}]}