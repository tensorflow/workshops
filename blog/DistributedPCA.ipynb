{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DistributedPCA.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnOyukkl8nKK",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright &copy; 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9vH6if28DN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02W7JBRLhFKy",
        "colab_type": "text"
      },
      "source": [
        "# Distributed PCA Using TensorFlow Extended (TFX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDW8q0rIKvSO",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "First, install dependencies, import modules, set up paths, and download data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlbGmqp9K1cO",
        "colab_type": "text"
      },
      "source": [
        "### Install dependencies\n",
        "\n",
        "> #### Note\n",
        "> Because of some of the updates to packages you must use the button at the bottom of the output of this cell to restart the runtime.  Following restart, you should rerun this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmN8W2pWK3bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorflow==2.0.0 pyarrow==0.14.1 tfx==0.15.0 grpcio==1.24.3 matplotlib==3.1.2\n",
        "!pip freeze | grep -e tensorflow -e tfx -e pyarrow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnyc-vjUK61V",
        "colab_type": "text"
      },
      "source": [
        "### Import packages\n",
        "We import necessary packages, including standard TFX component classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxInTpntK7eM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import absl\n",
        "import tempfile\n",
        "import urllib\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt    \n",
        "import matplotlib.patches as mpatches\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "import tfx\n",
        "\n",
        "from tfx.components import CsvExampleGen\n",
        "from tfx.components import SchemaGen\n",
        "from tfx.components import StatisticsGen\n",
        "from tfx.components import Transform\n",
        "from tfx.orchestration import metadata\n",
        "from tfx.orchestration import pipeline\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "from tfx.utils.dsl_utils import external_input\n",
        "from tfx.types import artifact_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iklHTMYJK95g",
        "colab_type": "text"
      },
      "source": [
        "### Set up pipeline paths and logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJlKpefCK_Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up paths.\n",
        "_tfx_root = tfx.__path__[0]\n",
        "_taxi_root = os.path.join(_tfx_root, 'examples/iris_pca_example')\n",
        "\n",
        "# Set up logging.\n",
        "absl.logging.set_verbosity(absl.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL1wx87wK_-D",
        "colab_type": "text"
      },
      "source": [
        "### Download example data\n",
        "We download the sample dataset for use in our TFX pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSjOqlJ2LBFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the example data.\n",
        "_data_root = tempfile.mkdtemp(prefix='tfx-data')\n",
        "DATA_PATH = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/iris/data/iris.csv'\n",
        "with open(os.path.join(_data_root, 'data.csv'), 'wb') as f:\n",
        "    contents = urllib.request.urlopen(DATA_PATH).read()\n",
        "    f.write(contents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlm70kNVLCMN",
        "colab_type": "text"
      },
      "source": [
        "## Create the InteractiveContext\n",
        "We now create the interactive context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqAOelmhLDZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, we create an InteractiveContext using default parameters. This will\n",
        "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
        "# To use your own pipeline root or database, the optional properties\n",
        "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
        "# InteractiveContext. Calls to InteractiveContext are no-ops outside of the\n",
        "# notebook.\n",
        "context = InteractiveContext()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPSFRr4oLFZN",
        "colab_type": "text"
      },
      "source": [
        "## Run TFX components interactively\n",
        "Next, we construct TFX components and run each one interactively using within the interactive session to obtain `ExecutionResult` objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6U91KjbLHBj",
        "colab_type": "text"
      },
      "source": [
        "### ExampleGen\n",
        "`ExampleGen` brings data into the TFX pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VxpjWF2LIEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the packaged CSV input data.\n",
        "examples = external_input(_data_root)\n",
        "\n",
        "# Brings data into the pipeline or otherwise joins/converts training data.\n",
        "example_gen = CsvExampleGen(input=examples)\n",
        "context.run(example_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSNVxmYtLJxg",
        "colab_type": "text"
      },
      "source": [
        "### StatisticsGen (using Tensorflow Data Validation)\n",
        "`StatisticsGen` computes statistics for visualization and example validation. This uses the [Tensorflow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTJv1QIELN7r",
        "colab_type": "text"
      },
      "source": [
        "#### Run TFDV statistics computation using the StatisticsGen component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utcbaHElLPYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Computes statistics over data for visualization and example validation.\n",
        "statistics_gen = StatisticsGen(\n",
        "    examples=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6byH9EQLR2q",
        "colab_type": "text"
      },
      "source": [
        "#### Visualize the statistics result\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azJgbglLLUAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context.show(statistics_gen.outputs['statistics'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm4A1_69LVy5",
        "colab_type": "text"
      },
      "source": [
        "### SchemaGen (using Tensorflow Data Validation)\n",
        "`SchemaGen` generates a schema for your data based on computed statistics. This component also uses the [Tensorflow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started) library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyOtZEpvLZe3",
        "colab_type": "text"
      },
      "source": [
        "#### Run TFDV schema inference using the SchemaGen component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYPCRqT4La3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generates schema based on statistics files.\n",
        "schema_gen = SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    infer_feature_shape=False)\n",
        "context.run(schema_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwJHH0wJLdj2",
        "colab_type": "text"
      },
      "source": [
        "#### Visualize the inferred schema\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lLxeFe4LfhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context.show(schema_gen.outputs['schema'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBapmgCwLhCe",
        "colab_type": "text"
      },
      "source": [
        "### Transform\n",
        "`Transform` performs data transformations and feature engineering which are kept in sync for training and serving."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jKcOFUWLiIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_iris_pca_transform_module_file = 'iris_pca_transform.py'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL0GznhvLjo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile {_iris_pca_transform_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "LABEL_KEY = 'variety'\n",
        "\n",
        "def _fill_in_missing(x):\n",
        "    \"\"\"Replace missing valueimport numpy as np\n",
        "    Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
        "    Args:\n",
        "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
        "      in the second dimension.\n",
        "    Returns:\n",
        "    A rank 1 tensor where missing values of `x` have been filled in.\n",
        "    \"\"\"\n",
        "    default_value = '' if x.dtype == tf.string else 0\n",
        "    return tf.sparse.to_dense(tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]), \n",
        "                              default_value)\n",
        "      \n",
        "def preprocessing_fn(inputs):\n",
        "    features = []\n",
        "    outputs = {\n",
        "        LABEL_KEY: _fill_in_missing(inputs[LABEL_KEY])\n",
        "    }\n",
        "    \n",
        "    for feature_name, feature_tensor in inputs.items():\n",
        "        if feature_name != LABEL_KEY:\n",
        "            features.append(tft.scale_to_z_score( # standard scaler pre-req for PCA\n",
        "                _fill_in_missing(feature_tensor)         # filling in missing values\n",
        "            ))\n",
        "\n",
        "    # concat to make feature matrix for PCA to run over\n",
        "    feature_matrix = tf.concat(features, axis=1)  \n",
        "    \n",
        "    # get orthonormal vector matix\n",
        "    orthonormal_vectors = tft.pca(feature_matrix, output_dim=2, dtype=tf.float32)\n",
        "    \n",
        "    # multiply matrix by feature matrix to get transformation\n",
        "    pca_examples = tf.linalg.matmul(feature_matrix, orthonormal_vectors)\n",
        "    \n",
        "    # unstack and add to output dict\n",
        "    pca_examples = tf.unstack(pca_examples, axis=1)\n",
        "    outputs['Principal Component 1'] = pca_examples[0]\n",
        "    outputs['Principal Component 2'] = pca_examples[1]\n",
        "      \n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osimseiSLlP_",
        "colab_type": "text"
      },
      "source": [
        "#### Run the Transform component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anY1ptZdLmgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Performs transformations and feature engineering in training and serving.\n",
        "transform = Transform(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=os.path.abspath(_iris_pca_transform_module_file))\n",
        "context.run(transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xqdQO9wMh2x",
        "colab_type": "text"
      },
      "source": [
        "#### Get transformed examples, for both train and eval set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eauaLZ8Ls6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating a tf.data.Dataset for the TFRecords\n",
        "transformed_examples_paths = [\n",
        "    artifact_utils.get_split_uri(transform.outputs['transformed_examples']._artifacts, 'train') + '*',\n",
        "    artifact_utils.get_split_uri(transform.outputs['transformed_examples']._artifacts, 'eval') + '*'\n",
        "]\n",
        "transformed_examples_path = [f for f in tf.data.Dataset.list_files(transformed_examples_paths)]\n",
        "transformed_dataset = tf.data.TFRecordDataset(transformed_examples_path, compression_type=\"GZIP\")\n",
        "\n",
        "# Utilizing tft.TFTransformOutput to get feature_spec\n",
        "transform_output = artifact_utils.get_single_uri(transform.outputs['transform_output']._artifacts)\n",
        "tf_transform_output = tft.TFTransformOutput(transform_output)\n",
        "feature_spec = tf_transform_output.transformed_feature_spec()\n",
        "\n",
        "# Parsing raw TFRecord into TFExamples\n",
        "def _parse_function(example_proto):\n",
        "    # Parse the input `tf.Example` proto using the feature_spec above.\n",
        "    return tf.io.parse_single_example(example_proto, feature_spec)\n",
        "\n",
        "transformed_dataset = transformed_dataset.map(_parse_function)\n",
        "print(\"Feature Spec: \")\n",
        "feature_spec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFkRy8GzLvnO",
        "colab_type": "text"
      },
      "source": [
        "#### Extract transformed data to standard numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN1DelMQLwx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pc1 , pc2, label_data = [], [], []\n",
        "label_data = []\n",
        "for f_dict in transformed_dataset:\n",
        "    pc1.append(f_dict['Principal Component 1'].numpy())\n",
        "    pc2.append(f_dict['Principal Component 2'].numpy())\n",
        "    label_data.append(f_dict['variety'].numpy()[0])\n",
        "pc1, pc2, label_data = np.array(pc1), np.array(pc2), np.array(label_data)\n",
        "pc1.shape[0], pc2.shape[0], label_data.shape[0]  # Should all be equal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDvEZkC3Lyo0",
        "colab_type": "text"
      },
      "source": [
        "#### Plot PCA data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmMeqLfxLzxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize = (10,6))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_title('Iris Dataset PCA', fontsize=20)\n",
        "\n",
        "for i in range(0, label_data.shape[0]):\n",
        "    color = 'red' if label_data[i]==0 else 'green' if label_data[i]==1 else 'purple'\n",
        "    ax.scatter(x=pc1[i], y=pc2[i], c=color, label=label_data[i], alpha=0.7)\n",
        "    \n",
        "ax.set_xlabel(\"Principal Component 1\")\n",
        "ax.set_ylabel(\"Principal Component 2\")\n",
        "plt.legend(handles=[mpatches.Patch(color='red', label='Iris-setosa'), \n",
        "                    mpatches.Patch(color='green', label='Iris-versicolor'), \n",
        "                    mpatches.Patch(color='purple', label='Iris-virginica')])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}